# Minix MOSEK-close code bundle (ipm2 scaffolding)
# This file is intended to be split into real files by split_minix_mosek_bundle.py
# Marker format: === <relative/path> ===

=== solver-core/src/ipm2/mod.rs ===
//! Experimental "ipm2" module: staging ground for MOSEK-close refactors.
//!
//! This module is intentionally additive: it can live side-by-side with the current ipm.
//! Wire it in via a feature flag or a settings knob so you can A/B against the existing solver.

pub mod diagnostics;
pub mod metrics;
pub mod modes;
pub mod perf;
pub mod regularization;
pub mod workspace;

pub use diagnostics::DiagnosticsConfig;
pub use metrics::{UnscaledMetrics, compute_unscaled_metrics};
pub use modes::{SolveMode, StallDetector};
pub use perf::{PerfSection, PerfTimers};
pub use regularization::{RegularizationPolicy, RegularizationState};
pub use workspace::IpmWorkspace;

=== solver-core/src/ipm2/diagnostics.rs ===
use std::env;

#[derive(Debug, Clone)]
pub struct DiagnosticsConfig {
    pub enabled: bool,
    pub every: usize,
    pub print_kkt_residuals: bool,
}

impl DiagnosticsConfig {
    pub fn from_env() -> Self {
        let enabled = match env::var("MINIX_DIAGNOSTICS") {
            Ok(v) => v != "0" && v.to_lowercase() != "false",
            Err(_) => false,
        };

        let every = env::var("MINIX_DIAGNOSTICS_EVERY")
            .ok()
            .and_then(|v| v.parse::<usize>().ok())
            .filter(|&v| v > 0)
            .unwrap_or(1);

        let print_kkt_residuals = env::var("MINIX_DIAGNOSTICS_KKT")
            .ok()
            .map(|v| v != "0" && v.to_lowercase() != "false")
            .unwrap_or(true);

        Self { enabled, every, print_kkt_residuals }
    }

    #[inline]
    pub fn should_log(&self, iter: usize) -> bool {
        self.enabled && (iter % self.every == 0)
    }
}

=== solver-core/src/ipm2/perf.rs ===
use std::time::{Duration, Instant};

#[derive(Debug, Copy, Clone)]
pub enum PerfSection {
    Residuals,
    Scaling,
    KktUpdate,
    Factorization,
    Solve,
    Termination,
    Other,
}

#[derive(Debug, Default, Clone)]
pub struct PerfTimers {
    pub residuals: Duration,
    pub scaling: Duration,
    pub kkt_update: Duration,
    pub factorization: Duration,
    pub solve: Duration,
    pub termination: Duration,
    pub other: Duration,
}

impl PerfTimers {
    pub fn scoped<'a>(&'a mut self, section: PerfSection) -> PerfGuard<'a> {
        PerfGuard { section, start: Instant::now(), timers: self }
    }

    pub fn add(&mut self, section: PerfSection, dt: Duration) {
        match section {
            PerfSection::Residuals => self.residuals += dt,
            PerfSection::Scaling => self.scaling += dt,
            PerfSection::KktUpdate => self.kkt_update += dt,
            PerfSection::Factorization => self.factorization += dt,
            PerfSection::Solve => self.solve += dt,
            PerfSection::Termination => self.termination += dt,
            PerfSection::Other => self.other += dt,
        }
    }
}

pub struct PerfGuard<'a> {
    section: PerfSection,
    start: Instant,
    timers: &'a mut PerfTimers,
}

impl Drop for PerfGuard<'_> {
    fn drop(&mut self) {
        self.timers.add(self.section, self.start.elapsed());
    }
}

=== solver-core/src/ipm2/workspace.rs ===
#[derive(Debug)]
pub struct IpmWorkspace {
    pub n: usize,
    pub m: usize,
    pub kkt_dim: usize,

    // Two RHS solves (two-solve strategy)
    pub rhs1: Vec<f64>,
    pub rhs2: Vec<f64>,
    pub sol1: Vec<f64>,
    pub sol2: Vec<f64>,

    // Termination / metrics scratch
    pub r_p: Vec<f64>,
    pub r_d: Vec<f64>,
    pub p_x: Vec<f64>,

    // Recovered/unscaled vectors (optional)
    pub x_bar: Vec<f64>,
    pub s_bar: Vec<f64>,
    pub z_bar: Vec<f64>,
}

impl IpmWorkspace {
    pub fn new(n: usize, m: usize) -> Self {
        let kkt_dim = n + m;
        Self {
            n,
            m,
            kkt_dim,
            rhs1: vec![0.0; kkt_dim],
            rhs2: vec![0.0; kkt_dim],
            sol1: vec![0.0; kkt_dim],
            sol2: vec![0.0; kkt_dim],
            r_p: vec![0.0; m],
            r_d: vec![0.0; n],
            p_x: vec![0.0; n],
            x_bar: vec![0.0; n],
            s_bar: vec![0.0; m],
            z_bar: vec![0.0; m],
        }
    }

    #[inline]
    pub fn clear_rhs(&mut self) {
        self.rhs1.fill(0.0);
        self.rhs2.fill(0.0);
    }

    #[inline]
    pub fn clear_solutions(&mut self) {
        self.sol1.fill(0.0);
        self.sol2.fill(0.0);
    }
}

=== solver-core/src/ipm2/regularization.rs ===
#[derive(Debug, Clone)]
pub struct RegularizationPolicy {
    pub static_reg: f64,
    pub static_reg_min: f64,
    pub static_reg_max: f64,
    pub dynamic_min_pivot: f64,

    // End-game / polish knobs
    pub polish_static_reg: f64,
    pub max_refine_iters: usize,
}

impl Default for RegularizationPolicy {
    fn default() -> Self {
        Self {
            static_reg: 1e-8,
            static_reg_min: 1e-12,
            static_reg_max: 1e-4,
            dynamic_min_pivot: 1e-13,
            polish_static_reg: 1e-10,
            max_refine_iters: 8,
        }
    }
}

#[derive(Debug, Copy, Clone)]
pub struct RegularizationState {
    pub static_reg_eff: f64,
    pub dynamic_bumps: u64,
    pub refine_iters: usize,
}

impl RegularizationPolicy {
    pub fn init_state(&self, scale: f64) -> RegularizationState {
        RegularizationState {
            static_reg_eff: self.effective_static_reg(scale),
            dynamic_bumps: 0,
            refine_iters: 1,
        }
    }

    #[inline]
    pub fn effective_static_reg(&self, scale: f64) -> f64 {
        let s = if scale.is_finite() { scale.max(1.0) } else { 1.0 };
        (self.static_reg * s).clamp(self.static_reg_min, self.static_reg_max)
    }

    #[inline]
    pub fn enter_polish(&self, st: &mut RegularizationState) {
        st.static_reg_eff = st.static_reg_eff.min(self.polish_static_reg);
        st.refine_iters = st.refine_iters.max(self.max_refine_iters);
    }
}

=== solver-core/src/ipm2/modes.rs ===
#[derive(Debug, Copy, Clone, Eq, PartialEq)]
pub enum SolveMode {
    Normal,
    StallRecovery,
    Polish,
}

#[derive(Debug, Clone)]
pub struct StallDetector {
    alpha_small_count: usize,
    dual_stall_count: usize,
    last_dual_res: f64,

    pub alpha_small_thresh: f64,
    pub alpha_small_iters: usize,

    pub dual_stall_iters: usize,
    pub dual_stall_rel_impr: f64,

    pub polish_mu_thresh: f64,
    pub polish_dual_mult: f64,
}

impl Default for StallDetector {
    fn default() -> Self {
        Self {
            alpha_small_count: 0,
            dual_stall_count: 0,
            last_dual_res: f64::INFINITY,

            alpha_small_thresh: 1e-6,
            alpha_small_iters: 5,

            dual_stall_iters: 10,
            dual_stall_rel_impr: 1e-3,

            polish_mu_thresh: 1e-10,
            polish_dual_mult: 10.0,
        }
    }
}

impl StallDetector {
    pub fn update(&mut self, alpha: f64, mu: f64, dual_res: f64, tol_feas: f64) -> SolveMode {
        // Alpha stall
        if alpha.is_finite() && alpha < self.alpha_small_thresh {
            self.alpha_small_count += 1;
        } else {
            self.alpha_small_count = 0;
        }

        // Dual residual stall
        if self.last_dual_res.is_finite() && dual_res.is_finite() {
            let rel_impr = (self.last_dual_res - dual_res) / self.last_dual_res.max(1e-18);
            if rel_impr.abs() < self.dual_stall_rel_impr {
                self.dual_stall_count += 1;
            } else {
                self.dual_stall_count = 0;
            }
        }
        self.last_dual_res = dual_res;

        let polish_trigger = mu.is_finite()
            && mu < self.polish_mu_thresh
            && dual_res.is_finite()
            && dual_res > self.polish_dual_mult * tol_feas;

        if polish_trigger {
            return SolveMode::Polish;
        }

        if self.alpha_small_count >= self.alpha_small_iters || self.dual_stall_count >= self.dual_stall_iters {
            return SolveMode::StallRecovery;
        }

        SolveMode::Normal
    }
}

=== solver-core/src/ipm2/metrics.rs ===
use sprs::CsMat;

#[derive(Debug, Copy, Clone)]
pub struct UnscaledMetrics {
    pub rp_inf: f64,
    pub rd_inf: f64,
    pub primal_scale: f64,
    pub dual_scale: f64,

    pub rel_p: f64,
    pub rel_d: f64,

    pub obj_p: f64,
    pub obj_d: f64,
    pub gap: f64,
    pub gap_rel: f64,
}

#[inline]
fn inf_norm(v: &[f64]) -> f64 {
    v.iter().fold(0.0, |acc, &x| acc.max(x.abs()))
}

#[inline]
fn dot(a: &[f64], b: &[f64]) -> f64 {
    a.iter().zip(b.iter()).map(|(ai, bi)| ai * bi).sum()
}

/// Compute unscaled metrics.
///
/// This function expects *already unscaled* `x_bar, s_bar, z_bar` (i.e., after:
/// 1) dividing by tau
/// 2) undoing Ruiz scaling).
///
/// It computes:
/// - r_p = A x_bar + s_bar - b
/// - r_d = P x_bar + A^T z_bar + q
/// - objectives + gap
///
/// The caller provides scratch buffers `r_p, r_d, p_x` to avoid allocations.
pub fn compute_unscaled_metrics(
    a: &CsMat<f64>,                  // m×n, CSC
    p_upper: Option<&CsMat<f64>>,    // n×n upper triangle (CSC) or full symmetric
    q: &[f64],
    b: &[f64],
    x_bar: &[f64],
    s_bar: &[f64],
    z_bar: &[f64],
    r_p: &mut [f64],
    r_d: &mut [f64],
    p_x: &mut [f64],
) -> UnscaledMetrics {
    let n = x_bar.len();
    let m = s_bar.len();

    debug_assert_eq!(a.rows(), m);
    debug_assert_eq!(a.cols(), n);
    debug_assert_eq!(b.len(), m);
    debug_assert_eq!(z_bar.len(), m);
    debug_assert_eq!(q.len(), n);
    debug_assert_eq!(r_p.len(), m);
    debug_assert_eq!(r_d.len(), n);
    debug_assert_eq!(p_x.len(), n);

    // r_p = A x + s - b
    r_p.copy_from_slice(s_bar);
    for i in 0..m {
        r_p[i] -= b[i];
    }
    for col in 0..n {
        if let Some(col_view) = a.outer_view(col) {
            let xj = x_bar[col];
            for (row, &val) in col_view.iter() {
                r_p[row] += val * xj;
            }
        }
    }

    // p_x = P x
    p_x.fill(0.0);
    if let Some(p) = p_upper {
        // Treat as symmetric: use stored entries and mirror off-diagonal.
        for col in 0..n {
            if let Some(col_view) = p.outer_view(col) {
                let xj = x_bar[col];
                for (row, &val) in col_view.iter() {
                    p_x[row] += val * xj;
                    if row != col {
                        p_x[col] += val * x_bar[row];
                    }
                }
            }
        }
    }

    // r_d = P x + A^T z + q
    r_d.copy_from_slice(&p_x[..n]);
    for i in 0..n {
        r_d[i] += q[i];
    }
    for col in 0..n {
        if let Some(col_view) = a.outer_view(col) {
            let mut acc = 0.0;
            for (row, &val) in col_view.iter() {
                acc += val * z_bar[row];
            }
            r_d[col] += acc;
        }
    }

    let rp_inf = inf_norm(r_p);
    let rd_inf = inf_norm(r_d);

    let b_inf = inf_norm(b);
    let q_inf = inf_norm(q);
    let x_inf = inf_norm(x_bar);
    let s_inf = inf_norm(s_bar);
    let z_inf = inf_norm(z_bar);

    let primal_scale = (b_inf + x_inf + s_inf).max(1.0);
    let dual_scale = (q_inf + x_inf + z_inf).max(1.0);

    let rel_p = rp_inf / primal_scale;
    let rel_d = rd_inf / dual_scale;

    let xpx = dot(x_bar, p_x);
    let qtx = dot(q, x_bar);
    let btz = dot(b, z_bar);

    let obj_p = 0.5 * xpx + qtx;
    let obj_d = -0.5 * xpx - btz;

    let gap = (obj_p - obj_d).abs();
    let denom = obj_p.abs().max(obj_d.abs()).max(1.0);
    let gap_rel = gap / denom;

    UnscaledMetrics {
        rp_inf,
        rd_inf,
        primal_scale,
        dual_scale,
        rel_p,
        rel_d,
        obj_p,
        obj_d,
        gap,
        gap_rel,
    }
}

