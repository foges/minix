--- a/solver-core/src/linalg/kkt.rs
+++ b/solver-core/src/linalg/kkt.rs
@@ -33,6 +33,27 @@
     }
 }
 
+struct SolveWorkspace {
+    rhs_perm: Vec<f64>,
+    sol_perm: Vec<f64>,
+    kx: Vec<f64>,
+    res: Vec<f64>,
+    delta: Vec<f64>,
+}
+
+impl SolveWorkspace {
+    fn new(kkt_dim: usize) -> Self {
+        Self {
+            rhs_perm: vec![0.0; kkt_dim],
+            sol_perm: vec![0.0; kkt_dim],
+            kx: vec![0.0; kkt_dim],
+            res: vec![0.0; kkt_dim],
+            delta: vec![0.0; kkt_dim],
+        }
+    }
+}
+
+
 /// KKT system solver.
 ///
 /// Manages the construction, factorization, and solution of KKT systems
@@ -56,6 +77,13 @@
 
     /// Inverse permutation (old index -> new index)
     perm_inv: Option<Vec<usize>>,
+
+    /// Fast-path: positions of diagonal entries of the -(H + 2εI) block inside `kkt_mat`.
+    /// Indexed by slack row `0..m` in the original (unpermuted) ordering.
+    h_diag_positions: Option<Vec<usize>>,
+
+    /// Workspace to make repeated solves allocation-free.
+    solve_ws: SolveWorkspace,
 }
 
 impl KktSolver {
@@ -79,6 +107,8 @@
             static_reg,
             perm: None,
             perm_inv: None,
+            h_diag_positions: None,
+            solve_ws: SolveWorkspace::new(kkt_dim),
         }
     }
 
@@ -226,12 +256,15 @@
                     // For SOC, the scaling matrix is H(w) = quadratic representation P(w)
                     // We need to compute the full dim x dim matrix and add -(H + 2ε*I) to KKT
                     let dim = w.len();
+                    let mut e_i = vec![0.0; dim];
+                    let mut col_i = vec![0.0; dim];
+
                     for i in 0..dim {
                         // Compute P(w) e_i to get column i of the matrix
-                        let mut e_i = vec![0.0; dim];
+                        e_i.fill(0.0);
                         e_i[i] = 1.0;
-
-                        let mut col_i = vec![0.0; dim];
+                        col_i.fill(0.0);
+
                         crate::scaling::nt::quad_rep_apply(w, &e_i, &mut col_i);
 
                         // Add upper triangle (j <= i) to avoid duplicates
@@ -286,6 +319,77 @@
         Ok(())
     }
 
+    fn compute_h_diag_positions(&self, kkt: &SparseCsc) -> Vec<usize> {
+        let kkt_dim = self.n + self.m;
+        assert_eq!(kkt.rows(), kkt_dim);
+        assert_eq!(kkt.cols(), kkt_dim);
+
+        let indptr = kkt.indptr();
+        let col_ptr = indptr.raw_storage();
+        let row_idx = kkt.indices();
+
+        let mut positions = vec![0usize; self.m];
+
+        for slack in 0..self.m {
+            let orig_idx = self.n + slack;
+            let col = if let Some(p_inv) = &self.perm_inv {
+                p_inv[orig_idx]
+            } else {
+                orig_idx
+            };
+
+            let start = col_ptr[col];
+            let end = col_ptr[col + 1];
+
+            let mut found = None;
+            for idx in start..end {
+                if row_idx[idx] == col {
+                    found = Some(idx);
+                    break;
+                }
+            }
+
+            positions[slack] = found.unwrap_or_else(|| {
+                panic!("KKT matrix missing diagonal entry at column {}", col);
+            });
+        }
+
+        positions
+    }
+
+    fn update_h_diagonal_in_place(&mut self, h_blocks: &[ScalingBlock]) {
+        let positions = self
+            .h_diag_positions
+            .as_ref()
+            .expect("H diagonal positions not initialized");
+        let kkt = self.kkt_mat.as_mut().expect("KKT matrix not initialized");
+        let data = kkt.data_mut();
+
+        let mut offset = 0usize;
+        for block in h_blocks {
+            match block {
+                ScalingBlock::Zero { dim } => {
+                    for i in 0..*dim {
+                        let slack = offset + i;
+                        data[positions[slack]] = -2.0 * self.static_reg;
+                    }
+                    offset += *dim;
+                }
+                ScalingBlock::Diagonal { d } => {
+                    for (i, &di) in d.iter().enumerate() {
+                        let slack = offset + i;
+                        data[positions[slack]] = -di - 2.0 * self.static_reg;
+                    }
+                    offset += d.len();
+                }
+                _ => panic!("update_h_diagonal_in_place called with non-diagonal ScalingBlock"),
+            }
+        }
+
+        assert_eq!(offset, self.m, "Scaling blocks must cover all {} slacks", self.m);
+    }
+
+
     /// Factor the KKT system.
     ///
     /// Performs numeric factorization with the current values of P, A, and H.
@@ -296,9 +400,32 @@
         a: &SparseCsc,
         h_blocks: &[ScalingBlock],
     ) -> Result<QdldlFactorization, QdldlError> {
+        let diag_h = h_blocks
+            .iter()
+            .all(|b| matches!(b, ScalingBlock::Zero { .. } | ScalingBlock::Diagonal { .. }));
+
+        if diag_h {
+            if self.kkt_mat.is_none() {
+                // Fallback: build once if initialize() was not called.
+                self.kkt_mat = Some(self.build_kkt_matrix(p, a, h_blocks));
+            }
+            if self.h_diag_positions.is_none() {
+                let kkt_ref = self.kkt_mat.as_ref().expect("KKT matrix not initialized");
+                self.h_diag_positions = Some(self.compute_h_diag_positions(kkt_ref));
+            }
+
+            self.update_h_diagonal_in_place(h_blocks);
+
+            let kkt_ref = self.kkt_mat.as_ref().expect("KKT matrix not initialized");
+            return self.qdldl.numeric_factorization(kkt_ref);
+        }
+
+        // General path: rebuild the full KKT matrix (needed for dense cone blocks like SOC).
+        self.h_diag_positions = None;
         let kkt = self.build_kkt_matrix(p, a, h_blocks);
-        self.kkt_mat = Some(kkt.clone());
-        self.qdldl.numeric_factorization(&kkt)
+        self.kkt_mat = Some(kkt);
+        let kkt_ref = self.kkt_mat.as_ref().expect("KKT matrix not initialized");
+        self.qdldl.numeric_factorization(kkt_ref)
     }
 
     /// Solve a single KKT system: K * [dx; dz] = [rhs_x; rhs_z].
@@ -311,7 +438,7 @@
     /// * `sol_x` - Solution for x block (output, length n)
     /// * `sol_z` - Solution for z block (output, length m)
     pub fn solve(
-        &self,
+        &mut self,
         factor: &QdldlFactorization,
         rhs_x: &[f64],
         rhs_z: &[f64],
@@ -323,7 +450,7 @@
 
     /// Solve with optional iterative refinement.
     pub fn solve_refined(
-        &self,
+        &mut self,
         factor: &QdldlFactorization,
         rhs_x: &[f64],
         rhs_z: &[f64],
@@ -335,7 +462,7 @@
     }
 
     fn solve_with_refinement(
-        &self,
+        &mut self,
         factor: &QdldlFactorization,
         rhs_x: &[f64],
         rhs_z: &[f64],
@@ -350,45 +477,55 @@
 
         // Assemble and permute RHS (if needed)
         let kkt_dim = self.n + self.m;
-        let mut rhs_perm = vec![0.0; kkt_dim];
         if let Some(p) = &self.perm {
             for i in 0..kkt_dim {
                 let src = p[i];
                 if src < self.n {
-                    rhs_perm[i] = rhs_x[src];
+                    self.solve_ws.rhs_perm[i] = rhs_x[src];
                 } else {
-                    rhs_perm[i] = rhs_z[src - self.n];
+                    self.solve_ws.rhs_perm[i] = rhs_z[src - self.n];
                 }
             }
         } else {
-            rhs_perm[..self.n].copy_from_slice(rhs_x);
-            rhs_perm[self.n..].copy_from_slice(rhs_z);
+            self.solve_ws.rhs_perm[..self.n].copy_from_slice(rhs_x);
+            self.solve_ws.rhs_perm[self.n..].copy_from_slice(rhs_z);
         }
 
         // Solve permuted system
-        let mut sol_perm = vec![0.0; kkt_dim];
-        self.qdldl.solve(factor, &rhs_perm, &mut sol_perm);
+        self.qdldl
+            .solve(factor, &self.solve_ws.rhs_perm, &mut self.solve_ws.sol_perm);
 
         if refine_iters > 0 {
             if let Some(kkt) = &self.kkt_mat {
-                let mut kx = vec![0.0; kkt_dim];
-                let mut res = vec![0.0; kkt_dim];
-                let mut delta = vec![0.0; kkt_dim];
-
                 for _ in 0..refine_iters {
-                    symm_matvec_upper(kkt, &sol_perm, &mut kx);
+                    symm_matvec_upper(kkt, &self.solve_ws.sol_perm, &mut self.solve_ws.kx);
+
+                    // QDLDL solves (K + εI)x=b; apply the same shift in residual evaluation.
+                    if self.static_reg != 0.0 {
+                        for i in 0..kkt_dim {
+                            self.solve_ws.kx[i] += self.static_reg * self.solve_ws.sol_perm[i];
+                        }
+                    }
+
                     for i in 0..kkt_dim {
-                        res[i] = rhs_perm[i] - kx[i];
-                    }
-
-                    let res_norm = res.iter().map(|v| v * v).sum::<f64>().sqrt();
+                        self.solve_ws.res[i] = self.solve_ws.rhs_perm[i] - self.solve_ws.kx[i];
+                    }
+
+                    let res_norm = self
+                        .solve_ws
+                        .res
+                        .iter()
+                        .map(|v| v * v)
+                        .sum::<f64>()
+                        .sqrt();
                     if !res_norm.is_finite() || res_norm < 1e-12 {
                         break;
                     }
 
-                    self.qdldl.solve(factor, &res, &mut delta);
+                    self.qdldl
+                        .solve(factor, &self.solve_ws.res, &mut self.solve_ws.delta);
                     for i in 0..kkt_dim {
-                        sol_perm[i] += delta[i];
+                        self.solve_ws.sol_perm[i] += self.solve_ws.delta[i];
                     }
                 }
             }
@@ -397,14 +534,14 @@
         // Unpermute solution back to original ordering
         if let Some(p_inv) = &self.perm_inv {
             for i in 0..self.n {
-                sol_x[i] = sol_perm[p_inv[i]];
+                sol_x[i] = self.solve_ws.sol_perm[p_inv[i]];
             }
             for i in 0..self.m {
-                sol_z[i] = sol_perm[p_inv[self.n + i]];
+                sol_z[i] = self.solve_ws.sol_perm[p_inv[self.n + i]];
             }
         } else {
-            sol_x.copy_from_slice(&sol_perm[..self.n]);
-            sol_z.copy_from_slice(&sol_perm[self.n..]);
+            sol_x.copy_from_slice(&self.solve_ws.sol_perm[..self.n]);
+            sol_z.copy_from_slice(&self.solve_ws.sol_perm[self.n..]);
         }
     }
 
@@ -418,7 +555,7 @@
     /// factorization is reused.
     #[allow(clippy::too_many_arguments)]
     pub fn solve_two_rhs(
-        &self,
+        &mut self,
         factor: &QdldlFactorization,
         rhs_x1: &[f64],
         rhs_z1: &[f64],
--- a/solver-core/src/linalg/qdldl.rs
+++ b/solver-core/src/linalg/qdldl.rs
@@ -63,6 +63,17 @@
 
     /// Number of dynamic regularization bumps applied
     dynamic_bumps: u64,
+
+    /// Cached diagonal positions (col -> index in CSC data) for applying static regularization
+    diag_positions: Option<Vec<Option<usize>>>,
+
+    /// Reusable workspace for the matrix values (A_x + static_reg on diagonal)
+    a_x_work: Vec<f64>,
+
+    /// Reusable factorization workspaces (allocated once)
+    bwork: Vec<ldl::Marker>,
+    iwork: Vec<usize>,
+    fwork: Vec<f64>,
 }
 
 /// Internal storage for LDL factorization
@@ -103,6 +114,11 @@
             static_reg,
             dynamic_reg_min_pivot,
             dynamic_bumps: 0,
+            diag_positions: None,
+            a_x_work: Vec::new(),
+            bwork: vec![ldl::Marker::Unused; n],
+            iwork: vec![0; 3 * n],
+            fwork: vec![0.0; n],
         }
     }
 
@@ -146,6 +162,21 @@
             Ok(_) => {
                 self.etree = Some(etree);
                 self.l_nz = Some(l_nz);
+
+                // Cache diagonal positions for fast static-regularization application.
+                let mut diag_positions = vec![None; self.n];
+                for col in 0..self.n {
+                    let start = a_p[col];
+                    let end = a_p[col + 1];
+                    for idx in start..end {
+                        if a_i[idx] == col {
+                            diag_positions[col] = Some(idx);
+                            break;
+                        }
+                    }
+                }
+                self.diag_positions = Some(diag_positions);
+
                 Ok(())
             }
             Err(_) => Err(QdldlError::FactorizationFailed),
@@ -178,16 +209,30 @@
         let a_i = mat.indices();
         let a_x_orig = mat.data();
 
-        // Apply static regularization to diagonal
-        let mut a_x = a_x_orig.to_vec();
+        // Ensure a_x workspace is allocated
+        if self.a_x_work.len() != a_x_orig.len() {
+            self.a_x_work.resize(a_x_orig.len(), 0.0);
+        }
+        self.a_x_work.copy_from_slice(a_x_orig);
+
+        // Apply static regularization to diagonal (fast via cached diagonal positions)
         if self.static_reg > 0.0 {
-            for col in 0..self.n {
-                let start = a_p[col];
-                let end = a_p[col + 1];
-                for idx in start..end {
-                    if a_i[idx] == col {
-                        // Diagonal entry
-                        a_x[idx] += self.static_reg;
+            if let Some(diag_pos) = &self.diag_positions {
+                for col in 0..self.n {
+                    if let Some(idx) = diag_pos[col] {
+                        self.a_x_work[idx] += self.static_reg;
+                    }
+                }
+            } else {
+                // Fallback (should not happen): scan for diagonal entries.
+                for col in 0..self.n {
+                    let start = a_p[col];
+                    let end = a_p[col + 1];
+                    for idx in start..end {
+                        if a_i[idx] == col {
+                            self.a_x_work[idx] += self.static_reg;
+                            break;
+                        }
                     }
                 }
             }
@@ -200,34 +245,57 @@
         // Compute total nonzeros in L from l_nz (fill-in can make L larger than A)
         let nnz_l: usize = l_nz.iter().sum();
 
-        // Allocate workspace for factorization
-        let mut l_p = vec![0; self.n + 1];
-        let mut l_i = vec![0; nnz_l];
-        let mut l_x = vec![0.0; nnz_l];
-        let mut d = vec![0.0; self.n];
-        let mut d_inv = vec![0.0; self.n];
-
-        // Workspace arrays
-        let mut bwork = vec![ldl::Marker::Unused; self.n];
-        let mut iwork = vec![0; 3 * self.n];
-        let mut fwork = vec![0.0; self.n];
+        // Ensure factorization buffers exist and are correctly sized
+        if self.factorization.is_none() {
+            self.factorization = Some(LdlFactorData {
+                l_p: vec![0; self.n + 1],
+                l_i: vec![0; nnz_l],
+                l_x: vec![0.0; nnz_l],
+                d: vec![0.0; self.n],
+                d_inv: vec![0.0; self.n],
+            });
+        } else {
+            let f = self.factorization.as_mut().unwrap();
+            if f.l_p.len() != self.n + 1 {
+                f.l_p.resize(self.n + 1, 0);
+            }
+            if f.l_i.len() != nnz_l {
+                f.l_i.resize(nnz_l, 0);
+            }
+            if f.l_x.len() != nnz_l {
+                f.l_x.resize(nnz_l, 0.0);
+            }
+            if f.d.len() != self.n {
+                f.d.resize(self.n, 0.0);
+            }
+            if f.d_inv.len() != self.n {
+                f.d_inv.resize(self.n, 0.0);
+            }
+        }
+
+        let f = self.factorization.as_mut().unwrap();
+
+        // Reset workspaces (ldl expects clean markers)
+        self.bwork.fill(ldl::Marker::Unused);
+        self.iwork.fill(0);
+        self.fwork.fill(0.0);
 
         // Perform factorization
         let result = ldl::factor(
             self.n,
             a_p,
             a_i,
-            &a_x,
-            &mut l_p,
-            &mut l_i,
-            &mut l_x,
-            &mut d,
-            &mut d_inv,
-            &l_nz,
+            &self.a_x_work,
+            &mut f.l_p,
+            &mut f.l_i,
+            &mut f.l_x,
+            &mut f.d,
+            &mut f.d_inv,
+            l_nz,
             etree,
-            &mut bwork,
-            &mut iwork,
-            &mut fwork,
+            &mut self.bwork,
+            &mut self.iwork,
+            &mut self.fwork,
         );
 
         // Check for factorization failure
@@ -236,28 +304,20 @@
                 // Apply dynamic regularization if needed
                 self.dynamic_bumps = 0;
                 for i in 0..self.n {
-                    if d[i].abs() < self.dynamic_reg_min_pivot {
-                        d[i] = if d[i] >= 0.0 {
+                    if f.d[i].abs() < self.dynamic_reg_min_pivot {
+                        f.d[i] = if f.d[i] >= 0.0 {
                             self.dynamic_reg_min_pivot
                         } else {
                             -self.dynamic_reg_min_pivot
                         };
-                        d_inv[i] = 1.0 / d[i];
+                        f.d_inv[i] = 1.0 / f.d[i];
                         self.dynamic_bumps += 1;
                     }
                 }
 
-                let factor_data = LdlFactorData {
-                    l_p,
-                    l_i,
-                    l_x,
-                    d: d.clone(),
-                    d_inv,
-                };
-
-                self.factorization = Some(factor_data);
-
-                Ok(QdldlFactorization { d_values: d })
+                Ok(QdldlFactorization {
+                    d_values: f.d.clone(),
+                })
             }
             Err(_) => Err(QdldlError::FactorizationFailed),
         }
--- a/solver-core/src/ipm/predcorr.rs
+++ b/solver-core/src/ipm/predcorr.rs
@@ -200,6 +200,7 @@
 pub fn predictor_corrector_step(
     kkt: &mut KktSolver,
     prob: &ProblemData,
+    neg_q: &[f64],
     state: &mut HsdeState,
     residuals: &HsdeResiduals,
     cones: &[Box<dyn ConeKernel>],
@@ -209,6 +210,8 @@
 ) -> Result<StepResult, String> {
     let n = prob.num_vars();
     let m = prob.num_constraints();
+
+    assert_eq!(neg_q.len(), n, "neg_q must have length n");
 
     // ======================================================================
     // Step 1: Compute NT scaling for all cones with adaptive regularization
@@ -353,8 +356,8 @@
     // (design doc §5.4.1)
     let mut dx2 = vec![0.0; n];
     let mut dz2 = vec![0.0; m];
-    let rhs_x2: Vec<f64> = prob.q.iter().map(|&qi| -qi).collect();
-    let rhs_z2 = prob.b.clone();
+    let rhs_x2 = neg_q;
+    let rhs_z2 = &prob.b;
 
     kkt.solve_refined(
         &factor,
--- a/solver-core/src/ipm/mod.rs
+++ b/solver-core/src/ipm/mod.rs
@@ -59,6 +59,10 @@
         integrality: prob.integrality.clone(),
     };
 
+    // Precompute constant RHS used by the two-solve dtau strategy: rhs_x2 = -q.
+    let neg_q: Vec<f64> = scaled_prob.q.iter().map(|&v| -v).collect();
+
+
     // Build cone kernels from cone specs
     let cones = build_cones(&scaled_prob.cones)?;
 
@@ -166,6 +170,7 @@
         let step_result = match predictor_corrector_step(
             &mut kkt,
             &scaled_prob,
+            &neg_q,
             &mut state,
             &residuals,
             &cones,
